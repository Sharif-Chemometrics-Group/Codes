{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b0cdde",
   "metadata": {},
   "source": [
    "This script provides an interactive tool for visualizing hyperspectral imaging (HSI) data from `.mat` or `.npy` files. It displays a two-panel window showing a specific spectral band of the HSI cube on one side and a plot for spectral signatures on the other. Users can left-click a single pixel or click-and-drag to select a region of interest (ROI) on the image to plot its corresponding spectrum. The tool also allows for right-clicking on the spectral plot to clear all selections and pressing the `s` key to save the currently displayed spectra to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add13d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.io import loadmat\n",
    "\n",
    "def load_mat_data(filepath, variable_name=None, transpose=False):\n",
    "    \"\"\"\n",
    "    Loads a numerical array from a .mat file, trying both h5py and scipy.\n",
    "\n",
    "    This function is robust and can handle both modern (v7.3+) and legacy\n",
    "    .mat file formats. It can automatically detect the variable name or use a\n",
    "    specified one.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The full path to the .mat file.\n",
    "\n",
    "        variable_name (str, optional): The specific name of the variable to load\n",
    "            from the .mat file. If None, the function will attempt to load the\n",
    "            first non-private variable it finds. Defaults to None.\n",
    "\n",
    "        transpose (bool, optional): If True, the loaded data matrix will be\n",
    "            transposed before being returned. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "            np.array: The data loaded from the .mat file.\n",
    "    \"\"\"\n",
    "\n",
    "    try:  # Method 1: Try h5py (for v7.3+ .mat files)\n",
    "        with h5py.File(filepath, \"r\") as f:\n",
    "            if variable_name:\n",
    "                key = variable_name\n",
    "            else:\n",
    "                key = [k for k in f.keys() if not k.startswith(\"#\")][0]\n",
    "            data = np.array(f[key])\n",
    "        print(f\"Loaded '{filepath}' using h5py.\")\n",
    "    except Exception:  # Method 2: Try scipy.io.loadmat\n",
    "        try:\n",
    "            mat_contents = loadmat(filepath)\n",
    "            if variable_name:\n",
    "                key = variable_name\n",
    "            else:\n",
    "                key = [k for k in mat_contents.keys() if not k.startswith(\"__\")][0]\n",
    "            data = mat_contents[key]\n",
    "            print(f\"Loaded '{filepath}' using scipy.\")\n",
    "        except Exception as e:\n",
    "            raise IOError(f\"Failed to load data from {filepath}\") from e\n",
    "\n",
    "    if transpose:\n",
    "        data = data.T\n",
    "    print(f\"  Final matrix shape: {data.shape}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def interactive_hsi_plotter(\n",
    "    hsi_data,\n",
    "    reference_band,\n",
    "    wavelengths=None,\n",
    "    variable_name=None,\n",
    "    save_dir=\"hsi_spectra\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates an advanced, interactive plot for exploring HSI data.\n",
    "\n",
    "    Features:\n",
    "    - Displays a reference band image with a selection box that appears as you drag.\n",
    "    - LEFT-CLICK & DRAG to select a Region of Interest (ROI) and plot its average spectrum.\n",
    "    - LEFT-CLICK plots a single pixel's spectrum.\n",
    "    - RIGHT-CLICK on the spectrum plot to clear all plotted spectra.\n",
    "    - Press the 's' key to SAVE the currently plotted spectra to a CSV file.\n",
    "    - Displays live pixel coordinates in the status bar.\n",
    "\n",
    "    Args:\n",
    "        hsi_data (str or np.array): File path or pre-loaded 3D NumPy array [height, width, bands].\n",
    "\n",
    "        reference_band (int): The index of the band to display as the main image.\n",
    "\n",
    "        wavelengths (np.array, optional): An array of wavelength values for the x-axis.\n",
    "\n",
    "        variable_name (str, optional): The variable name inside the .mat file.\n",
    "\n",
    "        save_dir (str): Directory to save exported spectra into.\n",
    "    \"\"\"\n",
    "    hsi_cube = None\n",
    "    plot_title = \"Interactive HSI Explorer\"\n",
    "\n",
    "    if isinstance(hsi_data, str):\n",
    "        hsi_filepath = hsi_data\n",
    "        print(f\"\\n--- Loading HSI data from: {hsi_filepath} ---\")\n",
    "        plot_title = f\"Interactive HSI Explorer: {os.path.basename(hsi_filepath)}\"\n",
    "        if hsi_filepath.endswith(\".npy\"):\n",
    "            hsi_cube = np.load(hsi_filepath)\n",
    "        elif hsi_filepath.endswith(\".mat\"):\n",
    "            hsi_cube = load_mat_data(hsi_filepath, variable_name=variable_name)\n",
    "        else:\n",
    "            raise ValueError(\"File path must end in .npy or .mat\")\n",
    "    elif isinstance(hsi_data, np.ndarray):\n",
    "        print(\"\\n--- Using pre-loaded HSI data ---\")\n",
    "        hsi_cube = hsi_data\n",
    "    else:\n",
    "        raise TypeError(\"hsi_data must be a file path (str) or a NumPy array.\")\n",
    "\n",
    "    if hsi_cube.ndim != 3:\n",
    "        raise ValueError(\n",
    "            f\"Data must be a 3D cube (height, width, bands). Got {hsi_cube.ndim} dimensions.\"\n",
    "        )\n",
    "\n",
    "    height, width, n_bands = hsi_cube.shape\n",
    "    print(\n",
    "        f\"Data loaded successfully. Shape: (Height: {height}, Width: {width}, Bands: {n_bands})\"\n",
    "    )\n",
    "\n",
    "    # Plotting Setup\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    fig, (ax_img, ax_spec) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    fig.suptitle(plot_title, fontsize=16)\n",
    "\n",
    "    # Display the reference band image\n",
    "    ref_image = hsi_cube[:, :, reference_band]\n",
    "    ax_img.imshow(ref_image, cmap=\"jet\", aspect=\"auto\")\n",
    "    ax_img.set_title(f\"Reference Image (Band {reference_band})\")\n",
    "    ax_img.set_xlabel(\"Width\")\n",
    "    ax_img.set_ylabel(\"Height\")\n",
    "    ax_img.format_coord = (\n",
    "        lambda x, y: f\"x={int(x + 0.5)}, y={int(y + 0.5)}\"\n",
    "    )  # Live coordinates\n",
    "\n",
    "    # Prepare the spectrum plot\n",
    "    x_axis = wavelengths if wavelengths is not None else np.arange(n_bands)\n",
    "    x_label = \"Wavelength\" if wavelengths is not None else \"Band Number\"\n",
    "    ax_spec.set_title(\n",
    "        'Click/Drag on image. Right-click here to clear. Press \"s\" to save.'\n",
    "    )\n",
    "    ax_spec.set_xlabel(x_label)\n",
    "    ax_spec.set_ylabel(\"Intensity\")\n",
    "    ax_spec.grid(True)\n",
    "\n",
    "    # Interactivity State and Callbacks\n",
    "    # Store the state of the drag action\n",
    "    drag_state = {\"start_xy\": None, \"rect\": None}\n",
    "\n",
    "    def on_press(event):\n",
    "        \"\"\"Callback for mouse button press.\"\"\"\n",
    "        if event.inaxes != ax_img or event.button != 1:\n",
    "            return\n",
    "        drag_state[\"start_xy\"] = (event.xdata, event.ydata)\n",
    "        drag_state[\"rect\"] = Rectangle(\n",
    "            (event.xdata, event.ydata),\n",
    "            0,\n",
    "            0,\n",
    "            facecolor=\"red\",\n",
    "            edgecolor=\"black\",\n",
    "            alpha=0.2,\n",
    "            fill=True,\n",
    "        )\n",
    "        ax_img.add_patch(drag_state[\"rect\"])\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    def on_motion(event):\n",
    "        \"\"\"Callback for mouse motion (dragging).\"\"\"\n",
    "        if drag_state[\"start_xy\"] is None or event.inaxes != ax_img:\n",
    "            return\n",
    "        x0, y0 = drag_state[\"start_xy\"]\n",
    "        x1, y1 = event.xdata, event.ydata\n",
    "        drag_state[\"rect\"].set_width(x1 - x0)\n",
    "        drag_state[\"rect\"].set_height(y1 - y0)\n",
    "        drag_state[\"rect\"].set_xy((x0, y0))\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    def on_release(event):\n",
    "        \"\"\"Callback for mouse button release.\"\"\"\n",
    "        if drag_state[\"start_xy\"] is None or event.button != 1:\n",
    "            return\n",
    "\n",
    "        # Remove the visual rectangle\n",
    "        if drag_state[\"rect\"] in ax_img.patches:\n",
    "            drag_state[\"rect\"].remove()\n",
    "\n",
    "        x1, y1 = drag_state[\"start_xy\"]\n",
    "        x2, y2 = event.xdata, event.ydata\n",
    "\n",
    "        # Reset the drag state\n",
    "        drag_state[\"start_xy\"] = None\n",
    "        drag_state[\"rect\"] = None\n",
    "\n",
    "        if x2 is None or y2 is None:\n",
    "            return  # Click was outside axes\n",
    "\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "        if x1 == x2 and y1 == y2:  # Single pixel click\n",
    "            if 0 <= x1 < width and 0 <= y1 < height:\n",
    "                spectrum = hsi_cube[y1, x1, :]\n",
    "                label = f\"Pixel ({x1}, {y1})\"\n",
    "            else:\n",
    "                return\n",
    "        else:  # ROI selection\n",
    "            x_start, x_end = sorted([x1, x2])\n",
    "            y_start, y_end = sorted([y1, y2])\n",
    "            x_start, x_end = max(0, x_start), min(width - 1, x_end)\n",
    "            y_start, y_end = max(0, y_start), min(height - 1, y_end)\n",
    "            roi = hsi_cube[y_start : y_end + 1, x_start : x_end + 1, :]\n",
    "            spectrum = np.mean(roi, axis=(0, 1))\n",
    "            label = f\"ROI Avg ({x_start}:{x_end}, {y_start}:{y_end})\"\n",
    "\n",
    "        ax_spec.plot(x_axis, spectrum, label=label)\n",
    "        ax_spec.set_title(\"Spectra Comparison\")\n",
    "        ax_spec.legend()\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    def on_key_press(event):\n",
    "        \"\"\"Callback for saving spectra.\"\"\"\n",
    "        if event.key == \"s\":\n",
    "            if not ax_spec.lines:\n",
    "                print(\"No spectra to save.\")\n",
    "                return\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            from datetime import datetime\n",
    "\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_filename = os.path.join(save_dir, f\"spectra_{timestamp}.csv\")\n",
    "            header = \"wavelength,\" + \",\".join(\n",
    "                [line.get_label() for line in ax_spec.lines]\n",
    "            )\n",
    "            data_to_save = [line.get_ydata() for line in ax_spec.lines]\n",
    "            wavelength_data = x_axis if wavelengths is not None else np.arange(n_bands)\n",
    "            output_data = np.vstack([wavelength_data] + data_to_save).T\n",
    "            np.savetxt(\n",
    "                save_filename, output_data, delimiter=\",\", header=header, comments=\"\"\n",
    "            )\n",
    "            print(f\"\\nSpectra saved to: {save_filename}\")\n",
    "\n",
    "    def on_right_click(event):\n",
    "        \"\"\"Callback for clearing the plot.\"\"\"\n",
    "        if event.inaxes == ax_spec and event.button == 3:\n",
    "            ax_spec.clear()\n",
    "            ax_spec.set_title(\n",
    "                'Click/Drag on image. Right-click here to clear. Press \"s\" to save.'\n",
    "            )\n",
    "            ax_spec.set_xlabel(x_label)\n",
    "            ax_spec.set_ylabel(\"Intensity\")\n",
    "            ax_spec.grid(True)\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "    # Connect Events\n",
    "    fig.canvas.mpl_connect(\"key_press_event\", on_key_press)\n",
    "    fig.canvas.mpl_connect(\"button_press_event\", on_press)\n",
    "    fig.canvas.mpl_connect(\"motion_notify_event\", on_motion)\n",
    "    fig.canvas.mpl_connect(\"button_release_event\", on_release)\n",
    "    fig.canvas.mpl_connect(\"button_press_event\", on_right_click)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    print(\"--- Interactive plot is now active. Close the window to continue. ---\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    path = r\"path to your file\"\n",
    "\n",
    "    # Number of band in your data\n",
    "    bands = 993 \n",
    "    sample_wavelengths = np.linspace(400, 1000, bands)\n",
    "\n",
    "    interactive_hsi_plotter(\n",
    "        hsi_data=path, reference_band=450, wavelengths=sample_wavelengths\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328192f",
   "metadata": {},
   "source": [
    "This script provides a GUI built with OpenCV for manually\n",
    "selecting and extracting fixed-size Regions of Interest (ROIs) from Hyperspectral\n",
    "Imaging (HSI) data files. It is designed to process a directory of HSI files,\n",
    "allowing the user to visually inspect each image and save multiple rectangular ROIs\n",
    "of a predefined size.\n",
    "\n",
    "HOW IT WORKS:\n",
    "1.  Scanning: \n",
    "    The script recursively scans a specified input directory (`INPUT_DIR`)\n",
    "    for HSI files with `.mat` or `.npy` extensions.\n",
    "\n",
    "2.  Visualization: \n",
    "    For each HSI file found, it generates a single-channel greyscale\n",
    "    image for display purposes. This greyscale image is created by averaging all the\n",
    "    spectral bands of the HSI cube.\n",
    "\n",
    "3.  Interactive ROI Selection: It opens an OpenCV window displaying the greyscale image.\n",
    "     - A green rectangle, representing the ROI to be extracted, follows the user's mouse\n",
    "       cursor. The size of this rectangle is defined by `ROI_HEIGHT` and `ROI_WIDTH`.\n",
    "     - The box is centered on the cursor and is constrained to stay within the image\n",
    "       boundaries.\n",
    "\n",
    "4.  Saving ROIs:\n",
    "     - When the user presses the SPACEBAR, the script extracts the corresponding region\n",
    "       from the *original, full-depth HSI data cube* (not the greyscale preview).\n",
    "     - This extracted ROI is then saved as a new file in the specified output directory\n",
    "       (`OUTPUT_DIR`).\n",
    "     - The script preserves the subfolder structure from the input directory in the\n",
    "       output directory.\n",
    "     - Saved ROIs are marked with a persistent blue rectangle on the image for the\n",
    "       current session to prevent re-selection.\n",
    "       \n",
    "5.  File Handling:\n",
    "     - The script automatically handles both `.mat` (MATLAB) and `.npy` (NumPy) file formats.\n",
    "     - For `.mat` files, it intelligently tries to find the variable containing the HSI\n",
    "       data cube by looking for the largest 3D NumPy array in the file.\n",
    "     - When saving, it preserves the original file format.\n",
    "\n",
    "User Control:\n",
    " - Mouse Movement: Positions the green selection box.\n",
    " - SPACEBAR: Saves the HSI data within the current green box to a new file.\n",
    " - 'n' key: Skips the current image and moves to the next one.\n",
    " - 'q' key: Quits the program.\n",
    "\n",
    "Configuration:\n",
    "The user needs to set the `INPUT_DIR`, `OUTPUT_DIR`, `ROI_HEIGHT`, and `ROI_WIDTH`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration \n",
    "# 1. Directory containing your HSI files (can have subfolders).\n",
    "INPUT_DIR = \"Original Data\"\n",
    "\n",
    "# 2. Directory where the new, fixed-size ROIs will be saved.\n",
    "OUTPUT_DIR = \"Output\"\n",
    "\n",
    "# 3. The dimensions (height, width) of the rectangular ROI.\n",
    "ROI_HEIGHT = 20\n",
    "ROI_WIDTH = 20\n",
    "\n",
    "# Global variable for mouse position\n",
    "mouse_coords = (0, 0)\n",
    "\n",
    "\n",
    "def find_hsi_variable_in_mat(mat_contents):\n",
    "    \"\"\"For .mat files, automatically finds the most likely HSI data cube.\"\"\"\n",
    "    # Initialize variables to keep track of the best candidate for HSI data.\n",
    "    best_candidate_name, best_candidate_data, max_size = None, None, -1\n",
    "    # Iterate through all items in the loaded .mat file.\n",
    "    for key, value in mat_contents.items():\n",
    "        # Skip internal MATLAB variables which typically start with '__'.\n",
    "        if key.startswith(\"__\"):\n",
    "            continue\n",
    "        # Check if the item is a NumPy array, has 3 dimensions (height, width, bands),\n",
    "        # and is larger than any previous candidate found.\n",
    "        if isinstance(value, np.ndarray) and value.ndim == 3 and value.size > max_size:\n",
    "            # If it's a better candidate, update our tracking variables.\n",
    "            max_size, best_candidate_name, best_candidate_data = value.size, key, value\n",
    "    # Return the name and data of the largest 3D array found.\n",
    "    return best_candidate_name, best_candidate_data\n",
    "\n",
    "\n",
    "def load_hsi_file(file_path):\n",
    "    \"\"\"Loads HSI data from either a .mat or .npy file.\"\"\"\n",
    "    # Check if the file is a .mat file (case-insensitive).\n",
    "    if file_path.lower().endswith(\".mat\"):\n",
    "        # Load the entire .mat file into a dictionary.\n",
    "        mat_contents = scipy.io.loadmat(file_path)\n",
    "        # Automatically find the most likely HSI data and its variable name.\n",
    "        mat_var_name, hsi_data = find_hsi_variable_in_mat(mat_contents)\n",
    "        return hsi_data, mat_var_name\n",
    "    # Check if the file is a .npy file (case-insensitive).\n",
    "    elif file_path.lower().endswith(\".npy\"):\n",
    "        # Load the NumPy array directly from the file.\n",
    "        hsi_data = np.load(file_path)\n",
    "        # For .npy files, there's no MATLAB variable name, so return None for it.\n",
    "        return hsi_data, None\n",
    "    # If the file format is not supported, return None for both values.\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def save_hsi_file(file_path, hsi_data, mat_var_name=None):\n",
    "    \"\"\"Saves HSI data to either a .mat or .npy file.\"\"\"\n",
    "    # Check if the desired output file is a .mat file.\n",
    "    if file_path.lower().endswith(\".mat\"):\n",
    "        # Save the data as a .mat file, using the original variable name.\n",
    "        scipy.io.savemat(file_path, {mat_var_name: hsi_data})\n",
    "    # Check if the desired output file is a .npy file.\n",
    "    elif file_path.lower().endswith(\".npy\"):\n",
    "        # Save the data as a .npy file.\n",
    "        np.save(file_path, hsi_data)\n",
    "\n",
    "\n",
    "def create_greyscale_from_hsi(hsi_data):\n",
    "    \"\"\"Creates a single-channel 8-bit greyscale image from an HSI data cube.\"\"\"\n",
    "    # Create a 2D greyscale image by averaging the pixel values across all spectral bands (axis=2).\n",
    "    greyscale_img = np.mean(hsi_data, axis=2)\n",
    "    # Normalize the greyscale image to the range [0, 255] to make it displayable.\n",
    "    normalized_img = cv2.normalize(greyscale_img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # Convert the floating-point image to an 8-bit unsigned integer format required by OpenCV.\n",
    "    return normalized_img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def mouse_move_callback(event, x, y, flags, param):\n",
    "    \"\"\"A simple callback that just updates the global mouse coordinates.\"\"\"\n",
    "    global mouse_coords\n",
    "    # Check if the event is a mouse movement.\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        # Update the global mouse_coords variable with the current (x, y) position.\n",
    "        mouse_coords = (x, y)\n",
    "\n",
    "\n",
    "def process_files_with_sliding_window():\n",
    "    \"\"\"\n",
    "    Main function to loop through files and allow user to select ROIs.\n",
    "    \"\"\"\n",
    "    global mouse_coords\n",
    "\n",
    "    # 1. Find all files recursively\n",
    "    all_files = []\n",
    "    # Walk through the input directory and all its subdirectories.\n",
    "    for root, _, files in os.walk(INPUT_DIR):\n",
    "        for file in files:\n",
    "            # Check if the file has a supported extension.\n",
    "            if file.lower().endswith((\".mat\", \".npy\")):\n",
    "                # If so, add its full path to our list of files to process.\n",
    "                all_files.append(os.path.join(root, file))\n",
    "\n",
    "    # Check if any files were found.\n",
    "    if not all_files:\n",
    "        print(f\"Error: No .mat or .npy files found in '{INPUT_DIR}' or its subfolders.\")\n",
    "        return\n",
    "\n",
    "    # Print instructions for the user.\n",
    "    print(\"--- Starting Fixed-Size ROI Selector ---\")\n",
    "    print(f\"ROI size is set to: {ROI_WIDTH}x{ROI_HEIGHT} pixels (Width x Height).\")\n",
    "    print(\"Instructions:\")\n",
    "    print(\" - Move your mouse to position the selection box.\")\n",
    "    print(\" - Press SPACEBAR to SAVE the ROI inside the box (it will turn blue).\")\n",
    "    print(\" - Press 'n' to SKIP to the next image.\")\n",
    "    print(\" - Press 'q' to QUIT the program.\")\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "    # Loop through each found file, with a progress bar from tqdm.\n",
    "    for file_path in tqdm(all_files, desc=\"Processing files\"):\n",
    "        try:\n",
    "            # Load the HSI data from the current file.\n",
    "            hsi_data, mat_var_name = load_hsi_file(file_path)\n",
    "            # If loading failed, print a warning and skip to the next file.\n",
    "            if hsi_data is None:\n",
    "                print(\n",
    "                    f\"Warning: Could not load {os.path.basename(file_path)}. Skipping.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Prepare for display\n",
    "            # Get the dimensions (height, width, number of bands) of the HSI cube.\n",
    "            img_height, img_width, _ = hsi_data.shape\n",
    "\n",
    "            # Create a displayable 8-bit greyscale image from the HSI data.\n",
    "            base_img = create_greyscale_from_hsi(hsi_data)\n",
    "            # Convert the single-channel greyscale image to a 3-channel BGR image\n",
    "            # so we can draw colored rectangles on it.\n",
    "            base_img_bgr = cv2.cvtColor(base_img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            # Setup OpenCV window\n",
    "            window_name = f\"ROI Selector - {os.path.basename(file_path)}\"\n",
    "            cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)\n",
    "            # Link our mouse callback function to this specific window.\n",
    "            cv2.setMouseCallback(window_name, mouse_move_callback)\n",
    "\n",
    "            # Initialize a counter for the ROIs saved from this specific image.\n",
    "            roi_counter = 0\n",
    "            # A list to store the coordinates of saved ROIs for this image, to redraw them.\n",
    "            saved_rois_for_current_image = []\n",
    "\n",
    "            # Main interactive loop for the current image\n",
    "            while True:\n",
    "                # Create a fresh copy of the base image in each frame to avoid\n",
    "                # drawing artifacts from previous frames.\n",
    "                display_img = base_img_bgr.copy()\n",
    "\n",
    "                # Draw all the previously saved ROIs for this image in blue.\n",
    "                # This gives the user persistent feedback on what they've already saved.\n",
    "                for sx, sy, ex, ey in saved_rois_for_current_image:\n",
    "                    cv2.rectangle(\n",
    "                        display_img, (sx, sy), (ex, ey), (255, 0, 0), 2\n",
    "                    )  # Blue color, 2px thickness\n",
    "\n",
    "                # Calculate current ROI box coordinates, handling edges\n",
    "                # Calculate half-width and half-height for centering the box on the cursor.\n",
    "                half_w = ROI_WIDTH // 2\n",
    "                half_h = ROI_HEIGHT // 2\n",
    "                # Clamp the center coordinates to ensure the ROI box never goes outside\n",
    "                # the image boundaries.\n",
    "                center_x = np.clip(mouse_coords[0], half_w, img_width - half_w - 1)\n",
    "                center_y = np.clip(mouse_coords[1], half_h, img_height - half_h - 1)\n",
    "\n",
    "                # Calculate the top-left (start) and bottom-right (end) corners of the ROI box.\n",
    "                start_x = center_x - half_w\n",
    "                start_y = center_y - half_h\n",
    "                end_x = start_x + ROI_WIDTH\n",
    "                end_y = start_y + ROI_HEIGHT\n",
    "\n",
    "                # Draw the active ROI selection box in green.\n",
    "                cv2.rectangle(\n",
    "                    display_img, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2\n",
    "                ) # Green color, 2px thickness\n",
    "\n",
    "                # Display the image with the drawn rectangles.\n",
    "                cv2.imshow(window_name, display_img)\n",
    "                # Wait for a key press for 1 millisecond.\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "                # Handle user input\n",
    "                if key == ord(\"q\"):\n",
    "                    print(\"\\nQuitting program.\")\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return\n",
    "\n",
    "                elif key == ord(\"n\"):\n",
    "                    break\n",
    "\n",
    "                elif key == 32:\n",
    "                    # Increment the counter for this image's ROIs.\n",
    "                    roi_counter += 1\n",
    "\n",
    "                    # Crop the region from the original, full-depth HSI data cube.\n",
    "                    cropped_hsi = hsi_data[start_y:end_y, start_x:end_x, :]\n",
    "\n",
    "                    # Add the coordinates of this newly saved box to our list for persistent display.\n",
    "                    saved_rois_for_current_image.append(\n",
    "                        (start_x, start_y, end_x, end_y)\n",
    "                    )\n",
    "\n",
    "                    # Construct the output path to preserve subfolder structure\n",
    "                    # Get the relative path of the file's directory with respect to the input directory.\n",
    "                    relative_path = os.path.relpath(\n",
    "                        os.path.dirname(file_path), INPUT_DIR\n",
    "                    )\n",
    "                    # Join this relative path with the main output directory.\n",
    "                    final_output_dir = os.path.join(OUTPUT_DIR, relative_path)\n",
    "                    # Create the output directory if it doesn't exist.\n",
    "                    os.makedirs(final_output_dir, exist_ok=True)\n",
    "\n",
    "                    # Create a unique filename for the saved ROI.\n",
    "                    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "                    file_ext = os.path.splitext(file_path)[1]\n",
    "                    output_filename = f\"{base_filename}_roi_{roi_counter}{file_ext}\"\n",
    "                    output_path = os.path.join(final_output_dir, output_filename)\n",
    "\n",
    "                    # Save the cropped HSI data to the new file.\n",
    "                    save_hsi_file(output_path, cropped_hsi, mat_var_name)\n",
    "                    # Print a confirmation message.\n",
    "                    print(\n",
    "                        f\"  -> Saved ROI #{roi_counter} to {os.path.join(os.path.basename(final_output_dir), output_filename)}\"\n",
    "                    )\n",
    "            \n",
    "            # After breaking the loop (by pressing 'n'), destroy the current image window.\n",
    "            cv2.destroyWindow(window_name)\n",
    "\n",
    "        # Catch any exceptions that occur during file processing.\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"\\nAn error occurred while processing {os.path.basename(file_path)}: {e}\"\n",
    "            )\n",
    "            # Clean up any open windows in case of an error.\n",
    "            cv2.destroyAllWindows()\n",
    "            # Continue to the next file in the main loop.\n",
    "            continue\n",
    "\n",
    "    print(\"\\n--- All files processed. ---\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(INPUT_DIR):\n",
    "        print(\n",
    "            f\"Input directory '{INPUT_DIR}' not found. Please create it and add your files.\"\n",
    "        )\n",
    "    else:\n",
    "        process_files_with_sliding_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b14aa",
   "metadata": {},
   "source": [
    "This script is designed to train and evaluate a 2D Convolutional Neural Network (CNN) for\n",
    "classifying HSI data. It automates the entire pipeline, from\n",
    "loading pre-processed data to performing robust evaluation using stratified k-fold\n",
    "cross-validation.\n",
    "\n",
    "HOW IT WORKS:\n",
    "1.  Data Loading: \n",
    "    The script expects a main data folder (`main_data_folder`) that contains\n",
    "    subfolders for each class. Each subfolder should contain the pre-processed HSI samples\n",
    "    (e.g., fixed-size ROIs) as `.npy` files. It loads all these samples into memory.\n",
    "\n",
    "2.  Preprocessing:\n",
    "     - The loaded data and corresponding labels are converted into NumPy arrays.\n",
    "     - The labels (class names) are numerically encoded (e.g., 'ClassA' -> 0) and then\n",
    "       converted into a one-hot categorical format suitable for the model's output layer.\n",
    "     - The script also truncates the spectral bands to a specific number (985 in this case).\n",
    "\n",
    "3.  Model Definition:\n",
    "     - A user-defined 2D-CNN model is created using the Keras Functional API. This\n",
    "       architecture can be easily modified by the user to experiment with different layers.\n",
    "     - The architecture uses Depthwise Separable Convolutions. This is a highly efficient\n",
    "       method for HSI data that works in two steps:\n",
    "       a) The `DepthwiseConv2D` layer first processes each spectral band (channel)\n",
    "          independently, learning spatial features like edges and textures within that band.\n",
    "       b) The following 1x1 `Conv2D` (Pointwise Convolution) then combines the outputs from\n",
    "          all bands, allowing the model to learn the crucial spectral relationships and\n",
    "          patterns across the entire spectrum.\n",
    "          \n",
    "       This separation of concerns is computationally cheaper and often more effective than\n",
    "       a standard convolution for high-dimensional data.\n",
    "     - The model includes standard components like Batch Normalization, ReLU activation,\n",
    "       and MaxPooling.\n",
    "     - It ends with a series of Dense (fully connected) layers for classification,\n",
    "       using L2 regularization to prevent overfitting.\n",
    "     - The final output layer uses a 'softmax' activation function to produce class\n",
    "       probabilities.\n",
    "     - The model is compiled with the Adam optimizer and 'categorical_crossentropy' loss,\n",
    "       which is standard for multi-class classification.\n",
    "\n",
    "4.  Cross-Validation & Training:\n",
    "     - To ensure the model's performance is robust and not dependent on a single random\n",
    "       train-test split, the script uses Stratified K-Fold cross-validation. This technique\n",
    "       divides the data into 'k' folds (sets), ensuring that each fold has the same\n",
    "       proportion of class labels as the original dataset.\n",
    "     - The script iterates 'k' times. In each iteration (fold), it uses one fold as the\n",
    "       test set and the remaining k-1 folds as the training set.\n",
    "     - The model is trained on the training set and evaluated on the test set for each fold.\n",
    "     - The model from each fold is saved for later use.\n",
    "\n",
    "5.  Evaluation:\n",
    "     - After all folds are completed, the script calculates the average accuracy and\n",
    "       standard deviation across all folds, providing a reliable measure of the model's\n",
    "       overall performance.\n",
    "     - It also generates a comprehensive classification report (including precision, recall,\n",
    "       and F1-score for each class) based on the combined predictions from all folds.\n",
    "\n",
    "Configuration:\n",
    "The user needs to set the `main_data_folder`, `n_splits`, `epochs`, and `batch_size`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aeb8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    DepthwiseConv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    ReLU,\n",
    ")\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Configuration\n",
    "# 1. Path to the folder of small, pre-resized data.\n",
    "# This folder should contain subdirectories, where each subdirectory name is a class label.\n",
    "main_data_folder = \"fixed_size_rois\"\n",
    "\n",
    "# 2. Set the training parameters\n",
    "n_splits = 5 \n",
    "epochs = 100\n",
    "batch_size = 8 \n",
    "\n",
    "\n",
    "# A safety check to ensure the user has updated the default path.\n",
    "if (\n",
    "    not os.path.exists(main_data_folder)\n",
    "    or main_data_folder == \"path/to/your/main_data_folder\"\n",
    "):\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(\"!!! IMPORTANT: Please update the main_data_folder variable !!!\")\n",
    "    print(\"!!! with the correct path to your data before running.   !!!\")\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "else:\n",
    "    print(\"--- Starting HSI Model Training and Evaluation ---\")\n",
    "\n",
    "    # 1. Load All Pre-processed Data and Labels\n",
    "    print(f\"\\n[Phase 1] Loading pre-processed data from '{main_data_folder}'...\")\n",
    "\n",
    "    try:\n",
    "        # Automatically find class names by listing the subdirectories in the main data folder.\n",
    "        class_names = sorted(\n",
    "            [\n",
    "                d\n",
    "                for d in os.listdir(main_data_folder)\n",
    "                if os.path.isdir(os.path.join(main_data_folder, d))\n",
    "            ]\n",
    "        )\n",
    "        # Exit if no class subfolders are found.\n",
    "        if not class_names:\n",
    "            print(f\"Error: No subfolders found in '{main_data_folder}'.\")\n",
    "            exit()\n",
    "\n",
    "        print(f\"Found {len(class_names)} classes: {class_names}\")\n",
    "\n",
    "        # Initialize lists to hold all data samples and their corresponding labels.\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "\n",
    "        # Iterate through each class folder.\n",
    "        for class_name in class_names:\n",
    "            class_folder = os.path.join(main_data_folder, class_name)\n",
    "            # Find all .npy files within the class folder.\n",
    "            npy_files = [f for f in os.listdir(class_folder) if f.endswith(\".npy\")]\n",
    "            # Load each .npy file.\n",
    "            for file_name in npy_files:\n",
    "                file_path = os.path.join(class_folder, file_name)\n",
    "                try:\n",
    "                    hsi_data = np.load(file_path)\n",
    "                    # Append the loaded data and its class label to our lists.\n",
    "                    all_data.append(hsi_data)\n",
    "                    all_labels.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not load file {file_path}. Error: {e}\")\n",
    "\n",
    "        # Exit if no data could be loaded at all.\n",
    "        if not all_data:\n",
    "            print(\"Error: Failed to load any data. Aborting.\")\n",
    "            exit()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The main data folder was not found at '{main_data_folder}'.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"Successfully loaded {len(all_data)} total samples into memory.\")\n",
    "\n",
    "    # 2. Preprocess Data\n",
    "    print(\"\\n[Phase 2] Preprocessing data...\")\n",
    "\n",
    "    # Convert the lists of data and labels into NumPy arrays for efficient processing.\n",
    "    X = np.array(all_data)\n",
    "    y = np.array(all_labels)\n",
    "    # Truncate the spectral dimension to the first 985 bands.\n",
    "    X = X[:, :, :, :985]\n",
    "\n",
    "    # Label Encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "    input_shape = X.shape[1:]\n",
    "    num_classes = len(class_names)\n",
    "    print(f\"Input shape for model: {input_shape}\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "    # 3. Define the 2D-CNN Model\n",
    "    def create_2d_cnn_model(input_shape, num_classes):\n",
    "        \"\"\"Defines and compiles the 2D-CNN model architecture.\"\"\"\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        # A Depthwise Convolution applies a single filter per input channel (band).\n",
    "        x = DepthwiseConv2D(kernel_size=(3, 3), padding=\"same\")(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        # A 1x1 Convolution (Pointwise Convolution) is used to combine the features\n",
    "        # across all the bands.\n",
    "        x = Conv2D(32, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        # MaxPooling reduces the spatial dimensions (height, width) of the feature maps.\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(64, activation=\"relu\", kernel_regularizer=l2(0.001))(x)\n",
    "        x = Dense(128, activation=\"relu\", kernel_regularizer=l2(0.001))(x)\n",
    "        x = Dense(256, activation=\"relu\", kernel_regularizer=l2(0.001))(x)\n",
    "        outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(\n",
    "            optimizer=Adam(\n",
    "                learning_rate=0.00001\n",
    "            ),\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # 4. Cross-Validation and Training\n",
    "    print(f\"\\n[Phase 3] Starting {n_splits}-Fold Cross-Validation...\")\n",
    "\n",
    "    # Initialize StratifiedKFold to ensure class distribution is preserved in each fold.\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store results from each fold.\n",
    "    fold_accuracies = []\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "\n",
    "    # Loop through each fold created by StratifiedKFold.\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y_encoded)):\n",
    "        print(f\"\\n--- Processing Fold {fold + 1}/{n_splits} ---\")\n",
    "\n",
    "        # Split the data into training and testing sets for the current fold.\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y_categorical[train_index], y_categorical[test_index]\n",
    "        y_test_encoded = y_encoded[\n",
    "            test_index\n",
    "        ]\n",
    "\n",
    "        # Create a new, fresh model for each fold.\n",
    "        model = create_2d_cnn_model(input_shape, num_classes)\n",
    "\n",
    "        # Train the model on the training data for the current fold.\n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(\n",
    "                X_test,\n",
    "                y_test,\n",
    "            ), \n",
    "            verbose=1, \n",
    "        )\n",
    "\n",
    "        # Evaluate the final trained model on the test set for this fold.\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Save the trained model from the fold.\n",
    "        model_save_path = f\"trained_model_fold_{fold+1}.keras\"\n",
    "        print(f\"Saving model from fold {fold+1} to: {model_save_path}\")\n",
    "        model.save(model_save_path)\n",
    "\n",
    "        y_pred_probs = model.predict(X_test)\n",
    "        y_pred_encoded = np.argmax(y_pred_probs, axis=1)\n",
    "        all_true_labels.extend(y_test_encoded)\n",
    "        all_pred_labels.extend(y_pred_encoded)\n",
    "\n",
    "    # 5. Final Evaluation\n",
    "    print(\"\\n\\n[Phase 4] --- Final Evaluation Results ---\")\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    print(\n",
    "        f\"\\nAverage Cross-Validation Accuracy: {mean_accuracy:.4f} (+/- {std_accuracy:.4f})\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nOverall Classification Report:\")\n",
    "    report = classification_report(\n",
    "        all_true_labels, all_pred_labels, target_names=class_names\n",
    "    )\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b13234f",
   "metadata": {},
   "source": [
    "This script performs a post-training analysis on a set of HSI classification models\n",
    "(trained via cross-validation) to understand which spectral features are most important\n",
    "for identifying each class. It uses a technique called \"saliency mapping\" to visualize\n",
    "how the model make a decision. The final output is a single plot\n",
    "comparing the average \"salient\" spectral signatures for each class, averaged across all\n",
    "cross-validation folds for a robust result.\n",
    "\n",
    "HOW IT WORKS:\n",
    "1.  Loading Models & Data:\n",
    "    The script loads all the trained `.keras` models from the\n",
    "    specified folder. It also prepares to load the original HSI data samples for analysis.\n",
    "\n",
    "2.  Iteration Across Folds & Classes:\n",
    "     - The outer loop iterates through each saved model (representing each fold of CV).\n",
    "     - The inner loop iterates through each class defined by the user.\n",
    "\n",
    "3.  Saliency Map Generation: For each class, the script processes every\n",
    "     corresponding HSI sample to determine its \"salient spectrum\".\n",
    "     a) A saliency map is generated for the sample. This map is a greyscale image of the\n",
    "        same size as the input, where brighter pixels indicate regions that were more\n",
    "        influential in the model's decision to classify it as its correct class.\n",
    "     b) A threshold is calculated (e.g., the 99th percentile) to identify only the most\n",
    "        significant pixels from the saliency map.\n",
    "     c) This threshold creates a mask, highlighting the most important spatial locations.\n",
    "\n",
    "4.  Salient Spectrum Extraction:\n",
    "     - The mask is applied to the original HSI data cube.\n",
    "     - The script then calculates the average spectral signature of *only* the pixels\n",
    "       that were identified as significant by the mask. This gives the \"salient spectrum\"\n",
    "       for that one sample.\n",
    "\n",
    "5.  Multi-Level Averaging:\n",
    "     - The salient spectrums of all samples within a class are averaged together to get a\n",
    "       single, representative spectrum for that class *for that specific model/fold*.\n",
    "     - After processing all models, these per-fold class averages are themselves averaged\n",
    "       together. This final \"grand average\" is a robust representation of the important\n",
    "       spectral features for each class, as it's validated across all training folds.\n",
    "\n",
    "6.  Plotting: The final averaged salient spectrum for each class is plotted on a single\n",
    "     graph against a calculated wavelength axis (400-1000 nm). This allows for direct\n",
    "     visual comparison of the key spectral features that differentiate the classes.\n",
    "\n",
    "Configuration:\n",
    "The user must set the paths, the list of class names (in the correct order), and the\n",
    "significance percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "# 1. Path to the folder containing all your saved .keras models from the CV folds.\n",
    "MODELS_FOLDER_PATH = \"Results\\\\Full Class\"\n",
    "\n",
    "# 2. Path to the main data folder containing the class subfolders.\n",
    "MAIN_DATA_FOLDER = \"fixed_size_rois\"\n",
    "\n",
    "# 3. Path for the final output plot.\n",
    "OUTPUT_PLOT_PATH = \"cross_validated_class_spectrum_overlay.png\"\n",
    "\n",
    "# 4. The list of your class names, in the exact same sorted order as in your training script.\n",
    "CLASS_NAMES = [\n",
    "    \"Class 1\",\n",
    "    \"Class 2\",\n",
    "    \"Class 3\",\n",
    "    \"Class 4\",\n",
    "    \"Class 5\",\n",
    "    \"Class 6\",\n",
    "    \"Class 7\",\n",
    "]\n",
    "\n",
    "# 5. Set the percentile for pixels to be considered \"significant\".\n",
    "#    For example, 99 means only pixels in the top 1% of saliency scores are used.\n",
    "SIGNIFICANT_PIXEL_PERCENTILE = 99\n",
    "\n",
    "\n",
    "def analyze_and_average_spectrums_across_folds():\n",
    "    \"\"\"\n",
    "    Generates a class-average spectrum plot by averaging the results\n",
    "    from all trained models in the cross-validation folds.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Cross-Validated Global Salient Spectrum Analysis ---\")\n",
    "\n",
    "    # 1. Validate Configuration\n",
    "    # Check if the necessary input folders exist before starting.\n",
    "    if not os.path.exists(MODELS_FOLDER_PATH):\n",
    "        print(f\"Error: Models folder not found at '{MODELS_FOLDER_PATH}'.\")\n",
    "        return\n",
    "    if not os.path.exists(MAIN_DATA_FOLDER):\n",
    "        print(f\"Error: Main data folder not found at '{MAIN_DATA_FOLDER}'.\")\n",
    "        return\n",
    "\n",
    "    # Find all saved model files in the specified folder.\n",
    "    model_files = sorted(\n",
    "        [f for f in os.listdir(MODELS_FOLDER_PATH) if f.endswith(\".keras\")]\n",
    "    )\n",
    "    if not model_files:\n",
    "        print(f\"Error: No .keras model files found in '{MODELS_FOLDER_PATH}'.\")\n",
    "        return\n",
    "\n",
    "    # 2. Data structure to hold results from all folds\n",
    "    fold_results = {name: [] for name in CLASS_NAMES}\n",
    "\n",
    "    # 3. Outer Loop: Iterate Through Each Model/Fold\n",
    "    for model_file in tqdm(model_files, desc=\"Processing Folds\"):\n",
    "        try:\n",
    "            # Load the pre-trained Keras model.\n",
    "            model_path = os.path.join(MODELS_FOLDER_PATH, model_file)\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            # Prepare the model for saliency analysis by replacing the final activation\n",
    "            replace2linear = ReplaceToLinear()\n",
    "            saliency_tool = Saliency(model, model_modifier=replace2linear, clone=False)\n",
    "\n",
    "            # 4. Inner Loop: Iterate Through Each Class\n",
    "            for class_index, class_name in enumerate(CLASS_NAMES):\n",
    "                class_folder_path = os.path.join(MAIN_DATA_FOLDER, class_name)\n",
    "                if not os.path.exists(class_folder_path):\n",
    "                    continue\n",
    "\n",
    "                # List to hold the average spectrum from each sample of this class.\n",
    "                sample_average_spectrums = []\n",
    "                npy_files = sorted(\n",
    "                    [f for f in os.listdir(class_folder_path) if f.endswith(\".npy\")]\n",
    "                )\n",
    "                if not npy_files:\n",
    "                    continue\n",
    "\n",
    "                # Process each sample in the class\n",
    "                for file_name in npy_files:\n",
    "                    try:\n",
    "                        # Load a single HSI data sample.\n",
    "                        sample_path = os.path.join(class_folder_path, file_name)\n",
    "                        sample_hsi = np.load(sample_path)\n",
    "                        # Ensure the band count matches what the model was trained on.\n",
    "                        sample_hsi = sample_hsi[:, :, :985]\n",
    "                        # Add a batch dimension to the sample for model prediction.\n",
    "                        sample_batch = np.expand_dims(sample_hsi, axis=0)\n",
    "\n",
    "                        # Define the target for the saliency tool\n",
    "                        score = CategoricalScore([class_index])\n",
    "                        # Generate the saliency map. This calculates the gradient of the output\n",
    "                        # with respect to the input, indicating pixel importance.\n",
    "                        saliency_map = saliency_tool(\n",
    "                            score, sample_batch, smooth_samples=20, smooth_noise=0.05\n",
    "                        )\n",
    "                        # Remove the batch dimension from the resulting map.\n",
    "                        saliency_map_2d = saliency_map[0]\n",
    "\n",
    "                        # Calculate the threshold value for identifying significant pixels.\n",
    "                        threshold = np.percentile(\n",
    "                            saliency_map_2d, SIGNIFICANT_PIXEL_PERCENTILE\n",
    "                        )\n",
    "                        # Create a boolean mask where True indicates a significant pixel.\n",
    "                        significant_mask = saliency_map_2d >= threshold\n",
    "\n",
    "                        if np.any(significant_mask):\n",
    "                            # calculate the mean spectrum of only those significant pixels.\n",
    "                            avg_spec_for_sample = np.mean(\n",
    "                                sample_hsi[significant_mask], axis=0\n",
    "                            )\n",
    "                            sample_average_spectrums.append(avg_spec_for_sample)\n",
    "                    except Exception:\n",
    "                        continue \n",
    "\n",
    "                # Calculate the average spectrum for this entire class for the current fold.\n",
    "                if sample_average_spectrums:\n",
    "                    class_avg_for_fold = np.mean(sample_average_spectrums, axis=0)\n",
    "                    fold_results[class_name].append(class_avg_for_fold)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn error occurred while processing model {model_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 5. Calculate the Final Grand Average Across All Folds\n",
    "    final_class_spectrums = {}\n",
    "    # Iterate through the results collected from all folds.\n",
    "    for class_name, spectrum_list in fold_results.items():\n",
    "        if spectrum_list:\n",
    "            # Average the per-fold results to get the final, robust spectrum for each class.\n",
    "            final_class_spectrums[class_name] = np.mean(spectrum_list, axis=0)\n",
    "\n",
    "    if not final_class_spectrums:\n",
    "        print(\"\\nError: No data was processed successfully. Cannot generate plot.\")\n",
    "        return\n",
    "\n",
    "    # 6. Plot the Final Overlay Graph\n",
    "    num_bands = list(final_class_spectrums.values())[0].shape[0]\n",
    "    wavelengths = np.linspace(400, 1000, num_bands)\n",
    "\n",
    "    print(\"\\n--- Generating Final Comparison Plot ---\")\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    colors = plt.cm.get_cmap(\"tab10\", len(final_class_spectrums))\n",
    "\n",
    "    for i, (class_name, spectrum) in enumerate(final_class_spectrums.items()):\n",
    "        ax.plot(wavelengths, spectrum, label=class_name, color=colors(i))\n",
    "\n",
    "    ax.set_title(\"Cross-Validated Comparison of Average Salient Spectrums\", fontsize=16)\n",
    "    ax.set_xlabel(\"Wavelength (nm)\", fontsize=12)\n",
    "    ax.set_ylabel(\"Average Intensity / Reflectance\", fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    plt.savefig(OUTPUT_PLOT_PATH, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n--- Analysis complete. Final plot saved to '{OUTPUT_PLOT_PATH}' ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_and_average_spectrums_across_folds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13153f6",
   "metadata": {},
   "source": [
    "This script analyzes a set of trained HSI classification models (those\n",
    "using a depthwise separable convolution structure) to determine the overall importance\n",
    "of each spectral band for the classification task. Instead of looking at individual\n",
    "samples, it inspects the model's internal weights to find global patterns. The final\n",
    "output is a plot showing the calculated importance score for each spectral band,\n",
    "highlighting the bands the models collectively found most useful.\n",
    "\n",
    "HOW IT WORKS:\n",
    "1.  Loading Models: The script scans a specified folder and loads all trained `.keras`\n",
    "    models, assuming each model corresponds to a fold from a cross-validation process.\n",
    "\n",
    "2.  Weight Extraction:\n",
    "     - For each loaded model, the script searches for the first 1x1 `Conv2D` layer. In a\n",
    "       depthwise separable convolution block, this \"pointwise\" layer is responsible for\n",
    "       combining the features learned from each individual spectral band.\n",
    "     - The script extracts the weights of this layer. The magnitude (absolute value) of\n",
    "       these weights can be interpreted as a proxy for the importance the model has\n",
    "       assigned to each input band. A larger weight suggests the model relies more heavily\n",
    "       on the features from that corresponding band to make its decisions.\n",
    "     - It calculates the mean absolute weight for each band across all output filters.\n",
    "\n",
    "3.  Averaging Across Folds:\n",
    "     - The band importance vector calculated from each model (fold) is stored.\n",
    "     - After processing all models, these vectors are averaged together. This step ensures\n",
    "       the final result is robust and represents a consensus of importance across all\n",
    "       cross-validation folds, rather than being skewed by a single training run.\n",
    "\n",
    "4.  Plotting & Reporting:\n",
    "     - A wavelength axis is generated based on the specified spectral range (e.g., 400-1000 nm).\n",
    "     - The final average importance scores are plotted against their corresponding wavelengths.\n",
    "     - The script identifies the top N most important bands, prints their details (band index,\n",
    "       wavelength, and importance score) to the console, and highlights them on the plot\n",
    "       with vertical lines and text labels for easy identification.\n",
    "\n",
    "Configuration:\n",
    "The user must set the paths, the number of top bands to highlight, and the wavelength\n",
    "range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "# 1. Path to the folder containing all saved .keras models from the CV folds.\n",
    "MODELS_FOLDER_PATH = \"Results\\\\4 Class (1,3,5,7)\\\\depth wise\"\n",
    "\n",
    "# 2. Path for the final output plot.\n",
    "OUTPUT_PLOT_PATH = \"overall_band_importance.png\"\n",
    "\n",
    "# 3. Number of top bands to highlight on the plot.\n",
    "NUM_TOP_BANDS_TO_HIGHLIGHT = 10\n",
    "\n",
    "# 4. Define the spectral range of your data.\n",
    "START_WAVELENGTH = 400 \n",
    "END_WAVELENGTH = 1000\n",
    "\n",
    "\n",
    "def analyze_band_importance():\n",
    "    \"\"\"\n",
    "    Loads all trained models from a folder, calculates the average importance\n",
    "    of each spectral band, and plots the final result against wavelength.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Overall Band Importance Analysis ---\")\n",
    "\n",
    "    # 1. Find all saved .keras models\n",
    "    if not os.path.exists(MODELS_FOLDER_PATH):\n",
    "        print(f\"Error: Models folder not found at '{MODELS_FOLDER_PATH}'.\")\n",
    "        return\n",
    "\n",
    "    model_files = sorted(\n",
    "        [f for f in os.listdir(MODELS_FOLDER_PATH) if f.endswith(\".keras\")]\n",
    "    )\n",
    "    if not model_files:\n",
    "        print(f\"Error: No .keras model files found in '{MODELS_FOLDER_PATH}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(model_files)} models to analyze.\")\n",
    "\n",
    "    # List to store the importance vector from each model/fold.\n",
    "    all_fold_importances = []\n",
    "\n",
    "    # 2. Loop Through Each Model\n",
    "    for model_file in tqdm(model_files, desc=\"Analyzing models\"):\n",
    "        try:\n",
    "            # Load one of the trained models.\n",
    "            model_path = os.path.join(MODELS_FOLDER_PATH, model_file)\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "            # Find the target pointwise convolution layer\n",
    "            target_layer = None\n",
    "            for layer in model.layers:\n",
    "                if isinstance(layer, tf.keras.layers.Conv2D) and layer.kernel_size == (\n",
    "                    1,\n",
    "                    1,\n",
    "                ):\n",
    "                    target_layer = layer\n",
    "                    break\n",
    "\n",
    "            if target_layer is None:\n",
    "                print(\n",
    "                    f\"\\nWarning: Could not find a pointwise layer in {model_file}. Skipping.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Extract and process weights\n",
    "            weights, _ = target_layer.get_weights()\n",
    "            # The weights have a shape like (1, 1, num_bands, num_filters).\n",
    "            # Squeeze removes the dimensions of size 1, resulting in (num_bands, num_filters).\n",
    "            weights = np.squeeze(weights)\n",
    "            absolute_weights = np.abs(weights)\n",
    "            # For each band, calculate the mean importance across all filters in the layer.\n",
    "            mean_importance_per_band = np.mean(absolute_weights, axis=1)\n",
    "            all_fold_importances.append(mean_importance_per_band)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn error occurred while processing {model_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_fold_importances:\n",
    "        print(\"\\nError: Could not extract weights from any model. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # 3. Calculate the Final Average Importance\n",
    "    # Average the importance vectors from all folds to get a final, robust result.\n",
    "    final_average_importance = np.mean(all_fold_importances, axis=0)\n",
    "\n",
    "    # 4. Create the Wavelength Axis\n",
    "    num_bands = len(final_average_importance)\n",
    "    wavelengths = np.linspace(START_WAVELENGTH, END_WAVELENGTH, num_bands)\n",
    "\n",
    "    print(\"\\n--- Generating Final Band Importance Plot ---\")\n",
    "\n",
    "    # 5. Find and Print the Top N Most Important Bands\n",
    "    # Get the indices of the bands sorted by importance in descending order.\n",
    "    top_band_indices = np.argsort(final_average_importance)[::-1][\n",
    "        :NUM_TOP_BANDS_TO_HIGHLIGHT\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nTop {NUM_TOP_BANDS_TO_HIGHLIGHT} most important bands:\")\n",
    "\n",
    "    for i, band_index in enumerate(top_band_indices):\n",
    "        importance_score = final_average_importance[band_index]\n",
    "        wavelength = wavelengths[band_index]\n",
    "        print(\n",
    "            f\"  {i+1}. Band {band_index} (~{wavelength:.1f} nm) (Importance: {importance_score:.4f})\"\n",
    "        )\n",
    "\n",
    "    # 6. Plot the Results with Wavelength Axis\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    ax.plot(\n",
    "        wavelengths, final_average_importance, color=\"navy\", label=\"Average Importance\"\n",
    "    )\n",
    "\n",
    "    for band_index in top_band_indices:\n",
    "        importance_score = final_average_importance[band_index]\n",
    "        wavelength = wavelengths[band_index]\n",
    "        ax.axvline(x=wavelength, color=\"red\", linestyle=\"--\", alpha=0.7)\n",
    "        ax.text(\n",
    "            wavelength + 5,\n",
    "            importance_score,\n",
    "            f\"{wavelength:.0f} nm\",\n",
    "            color=\"red\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"Overall Importance of Each Spectral Band Across All CV Folds\", fontsize=16\n",
    "    )\n",
    "    ax.set_xlabel(\"Wavelength (nm)\", fontsize=12)\n",
    "    ax.set_ylabel(\"Average Absolute Weight (Importance)\", fontsize=12)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    ax.set_xlim(START_WAVELENGTH, END_WAVELENGTH)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.savefig(OUTPUT_PLOT_PATH, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n--- Analysis complete. Final plot saved to '{OUTPUT_PLOT_PATH}' ---\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_band_importance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
