{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ef55ed",
   "metadata": {},
   "source": [
    "Required Packages:\n",
    "\n",
    "gc-ims-tools: Custom package to handle and analyze GC-IMS data\n",
    "\n",
    "Pillow: For image handling (replacement for PIL)\n",
    "\n",
    "OpenCV: For image processing\n",
    "\n",
    "tensorflow: Deep learning framework (model, training, saliency maps)\n",
    "\n",
    "tf-keras-vis: For generating saliency maps (e.g., SmoothGrad, etc.)\n",
    "\n",
    "scikit-learn: For KFold, PCA, classification report, confusion matrix\n",
    "\n",
    "scikit-image: For peak detection\n",
    "\n",
    "numpy: For numerical array and matrix operations\n",
    "\n",
    "matplotlib: For plotting images and graphs\n",
    "\n",
    "seaborn: For enhanced plotting (e.g., confusion matrix heatmap)\n",
    "\n",
    "tqdm: For progress bars in loops\n",
    "\n",
    "Install all packages using pip:\n",
    "\n",
    "pip install gc-ims-tools tensorflow tf-keras-vis scikit-learn scikit-image matplotlib seaborn tqdm Pillow opencv-python\n",
    "\n",
    "_______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c56500a",
   "metadata": {},
   "source": [
    "The following script performs preprocessing of GC-IMS data for use in machine learning applications, such as CNN-based classification.\n",
    "The workflow includes data import, optional resolution reduction through binning, alignment of chromatograms using the\n",
    "Reactant Ion Peak (RIP), cropping of non-informative regions along both drift time and retention time axes,\n",
    "and exporting the resulting chromatograms as 2D heatmap images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b45f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the IMS package for processing GC-IMS data\n",
    "import ims\n",
    "\n",
    "# Load the dataset from the specified directory. The dataset contains .mea files,\n",
    "ds = ims.Dataset.read_mea(\n",
    "    r\"Dataset directory\",\n",
    "    subfolders=True,\n",
    ")\n",
    "print(\"Data Import Completed\")\n",
    "\n",
    "# Optional: Apply binning with a factor of 2 (reduce computational cost for system with limited RAM)\n",
    "ds_bin = ds.binning(2)\n",
    "print(\"Binning complete\")\n",
    "\n",
    "# Align chromatograms based on the Reactant Ion Peak (RIP) using relative interpolation.\n",
    "# This step is very memory intensive.\n",
    "ds_bin_rip = ds.interp_riprel()\n",
    "print(\"RIP complete\")\n",
    "\n",
    "# Crop the chromatograms to remove non-informative or noisy regions:\n",
    "# For Example:\n",
    "# - Drift time is restricted to the range of 1.05 to 2.5 ms relative to RIP.\n",
    "# - Retention time is limited to the range of 50 to 900 seconds.\n",
    "ds_cut = ds_bin_rip.cut_dt(1.05, 2.5).cut_rt(50, 900)\n",
    "print(\"Cut complete\")\n",
    "\n",
    "# Export the preprocessed chromatograms as 2D heatmap images (Image elements must be removed in the next step)\n",
    "ds_cut.export_plots(r\"Output directory\")\n",
    "print(\"Preprocessing Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23cf25d",
   "metadata": {},
   "source": [
    "The following script performs standardized cropping of GC-IMS chromatogram images generated in the previous preprocessing step.\n",
    "The cropping operation is necessary to isolate the informative central region of each heatmap while eliminating\n",
    "axes, legends, and other non-data elements introduced during plotting. The script preserves the original\n",
    "folder structure while saving the cropped images to a new output directory, maintaining consistency for downstream\n",
    "classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef713d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define the folder where images are stored\n",
    "input_folder = r\"Output directory of preprocessed chromatogram images\"\n",
    "output_folder = r\"Output directory for final heatmaps\"\n",
    "\n",
    "# Define the crop area (left, upper, right, lower)\n",
    "# Adjust these coordinates as per desired crop area\n",
    "crop_area = (227, 122, 1342, 1507)\n",
    "\n",
    "# Traverse through the input folder and its subfolders\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for image_name in files:\n",
    "        if image_name.endswith(\".jpg\"):\n",
    "            # Construct the full path to the image\n",
    "            image_path = os.path.join(root, image_name)\n",
    "\n",
    "            # Open the image file\n",
    "            img = Image.open(image_path)\n",
    "\n",
    "            # Crop the image using the defined crop area\n",
    "            cropped_img = img.crop(crop_area)\n",
    "\n",
    "            # Create corresponding subdirectory structure in the output folder\n",
    "            relative_path = os.path.relpath(root, input_folder)\n",
    "            output_subfolder = os.path.join(output_folder, relative_path)\n",
    "            os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "            # Save the cropped image to the corresponding output subfolder\n",
    "            cropped_img.save(os.path.join(output_subfolder, image_name))\n",
    "\n",
    "            print(f\"Cropped image {os.path.join(relative_path, image_name)} saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bc8ccf",
   "metadata": {},
   "source": [
    "This script implements a domain-specific data augmentation technique for GC-IMS chromatographic images, where peak regions are detected and selectively shifted vertically to simulate retention time variability The augmentation preserves chemical relevance by identifying peak locations using local maxima detection, \n",
    "then applying controlled directional shifts within predefined regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import peak_local_max\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def augment(image_path: str, output_path: str, direction: str):\n",
    "\n",
    "    # Parameters\n",
    "    Min_Peak_Distance = 15\n",
    "    Peak_Threshold = 0.4\n",
    "    Peak_Box_Size = 30\n",
    "    Max_Vertical_Shift = 8\n",
    "    Peak_Shift_Fraction = 0.5\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not read image {image_path}.\")\n",
    "        return False\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_normalized = img_gray.astype(np.float32) / 255.0\n",
    "\n",
    "    peak_coords = peak_local_max(\n",
    "        img_normalized, min_distance=Min_Peak_Distance, threshold_abs=Peak_Threshold\n",
    "    )\n",
    "\n",
    "    if len(peak_coords) == 0:\n",
    "        cv2.imwrite(output_path, img)\n",
    "        return True\n",
    "\n",
    "    augmented_img = np.copy(img)\n",
    "\n",
    "    num_to_shift = int(len(peak_coords) * Peak_Shift_Fraction)\n",
    "    if num_to_shift == 0 and len(peak_coords) > 0:\n",
    "        num_to_shift = 1\n",
    "\n",
    "    indices_to_shift = np.random.choice(\n",
    "        len(peak_coords), size=num_to_shift, replace=False\n",
    "    )\n",
    "\n",
    "    for i in indices_to_shift:\n",
    "        y_peak, x_peak = peak_coords[i]\n",
    "\n",
    "        if direction == \"up\":\n",
    "            # Shift must be negative (and not zero)\n",
    "            shift = random.randint(-Max_Vertical_Shift, -1)\n",
    "        elif direction == \"down\":\n",
    "            # Shift must be positive (and not zero)\n",
    "            shift = random.randint(1, Max_Vertical_Shift)\n",
    "        else:  # 'both'\n",
    "            shift = random.randint(-Max_Vertical_Shift, Max_Vertical_Shift)\n",
    "\n",
    "        if shift == 0:\n",
    "            continue\n",
    "\n",
    "        half_box = Peak_Box_Size // 2\n",
    "        y_start, y_end = y_peak - half_box, y_peak + half_box\n",
    "        x_start, x_end = x_peak - half_box, x_peak + half_box\n",
    "        new_y_start, new_y_end = y_start + shift, y_end + shift\n",
    "\n",
    "        if (\n",
    "            y_start < 0\n",
    "            or y_end > img.shape[0]\n",
    "            or x_start < 0\n",
    "            or x_end > img.shape[1]\n",
    "            or new_y_start < 0\n",
    "            or new_y_end > img.shape[0]\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Make a copy of the peak before modifying the image.\n",
    "        peak_roi = augmented_img[y_start:y_end, x_start:x_end].copy()\n",
    "\n",
    "        # Padding\n",
    "        if shift > 0:  # Moved DOWN\n",
    "            pad_source_y = max(0, y_start - 1)\n",
    "            pad_row = augmented_img[pad_source_y, x_start:x_end]\n",
    "            for y in range(y_start, y_end):\n",
    "                augmented_img[y, x_start:x_end] = pad_row\n",
    "        else:  # Moved UP\n",
    "            pad_source_y = min(img.shape[0] - 1, y_end)\n",
    "            pad_row = augmented_img[pad_source_y, x_start:x_end]\n",
    "            for y in range(y_start, y_end):\n",
    "                augmented_img[y, x_start:x_end] = pad_row\n",
    "\n",
    "        # Place the original peak into the new location.\n",
    "        augmented_img[new_y_start:new_y_end, x_start:x_end] = peak_roi\n",
    "\n",
    "    cv2.imwrite(output_path, augmented_img)\n",
    "    return True\n",
    "\n",
    "\n",
    "def process_dataset(\n",
    "    input_dir: str, output_dir: str, num_augmentations_per_image: int, direction: str\n",
    "):\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    print(f\"Input directory: {input_path}\")\n",
    "    print(f\"Output directory: {output_path}\")\n",
    "\n",
    "    image_files = (\n",
    "        list(input_path.glob(\"**/*.jpg\"))\n",
    "        + list(input_path.glob(\"**/*.png\"))\n",
    "        + list(input_path.glob(\"**/*.jpeg\"))\n",
    "    )\n",
    "    if not image_files:\n",
    "        print(\"Error: No images found in the input directory.\")\n",
    "        return\n",
    "\n",
    "    total_images = len(image_files)\n",
    "    print(f\"Found {total_images} images to process.\")\n",
    "\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        relative_path = image_file.relative_to(input_path)\n",
    "        output_original_path = output_path / relative_path\n",
    "\n",
    "        output_original_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(image_file, output_original_path)\n",
    "\n",
    "        for n in range(num_augmentations_per_image):\n",
    "            aug_stem = output_original_path.stem + f\"_aug_{n + 1}\"\n",
    "            aug_suffix = output_original_path.suffix\n",
    "            output_augmented_path = output_original_path.with_name(\n",
    "                f\"{aug_stem}{aug_suffix}\"\n",
    "            )\n",
    "\n",
    "            # Pass the direction parameter to the augmentation function\n",
    "            augment(str(image_file), str(output_augmented_path), direction)\n",
    "\n",
    "        print(\n",
    "            f\"({i+1}/{total_images}) Processed '{image_file.name}' -> saved original + {num_augmentations_per_image} augmented versions.\"\n",
    "        )\n",
    "\n",
    "    total_original = total_images\n",
    "    total_augmented = total_images * num_augmentations_per_image\n",
    "    grand_total = total_original + total_augmented\n",
    "    print(\"\\nProcessing complete.\")\n",
    "    print(\n",
    "        f\"Successfully created a new dataset with {grand_total} images in '{output_dir}'.\"\n",
    "    )\n",
    "    print(f\"({total_original} original + {total_augmented} augmented)\")\n",
    "\n",
    "\n",
    "#\n",
    "# Nomber of augmented versions for each original image\n",
    "Num_Augmentations_Per_Image = 2\n",
    "\n",
    "# Set the direction for the peak shift\n",
    "Shift_Direction = \"up\"  # Options: 'up', 'down', 'both'\n",
    "\n",
    "# Path to original dataset\n",
    "Input_Directory = r\"Output directory for final heatmaps\"\n",
    "\n",
    "# Path to augmented dataset\n",
    "Output_Directory = r\"Output directory for final heatmaps + Augmented images\"\n",
    "\n",
    "process_dataset(\n",
    "    Input_Directory,\n",
    "    Output_Directory,\n",
    "    Num_Augmentations_Per_Image,\n",
    "    Shift_Direction,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e399f7",
   "metadata": {},
   "source": [
    "The following script implements a CNN-based classification pipeline using k-fold cross-validation to evaluate the model's generalization performance across GC-IMS heatmap images.\n",
    "The pipeline includes model definition, image loading, cross-validated training, per-fold performance visualization, and statistical reporting of classification metrics with standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Define the CNN model architecture\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(\n",
    "        layers.Conv2D(\n",
    "            8, (3, 3), strides=(1, 1), padding=\"same\", input_shape=input_shape\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(48, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(layers.Dense(32, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "input_shape = (248, 200, 3)\n",
    "num_classes = 3\n",
    "batch_size = 4\n",
    "epochs = 50\n",
    "\n",
    "# Create an ImageDataGenerator to rescale pixel values\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Path to dataset directory containing class subfolders\n",
    "data_dir = r\"Directory for final heatmaps\"\n",
    "\n",
    "# Load all images and labels into memory\n",
    "dataset = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(248, 200),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Store all image batches into arrays\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(len(dataset)):\n",
    "    x_batch, y_batch = dataset[i]\n",
    "    X.append(x_batch)\n",
    "    Y.append(y_batch)\n",
    "X = np.concatenate(X)\n",
    "Y = np.concatenate(Y)\n",
    "\n",
    "# Initialize K-Fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "histories = []\n",
    "\n",
    "# Dictionary for storing precision, recall, and F1-score per class per fold\n",
    "test_metrics_per_class = defaultdict(list)\n",
    "\n",
    "# Begin k-fold training and evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, Y)):\n",
    "    print(f\"Training fold {fold + 1}...\")\n",
    "\n",
    "    # Build and compile a new model instance for this fold\n",
    "    model = create_cnn_model(input_shape, num_classes)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    Y_train, Y_val = Y[train_idx], Y[val_idx]\n",
    "\n",
    "    # Train the model and store training history\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1,\n",
    "    )\n",
    "    histories.append(history)\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    scores = model.evaluate(X_val, Y_val)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    print(\n",
    "        f\"Score for fold {fold + 1}: Loss = {scores[0]:.4f}; Accuracy = {scores[1] * 100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # Plot accuracy and loss for this fold\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\", linestyle=\"--\")\n",
    "    plt.title(f\"Fold {fold + 1} Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Val Loss\", linestyle=\"--\")\n",
    "    plt.title(f\"Fold {fold + 1} Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"accuracy_loss_fold_{fold + 1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save trained model for this fold\n",
    "    model.save(f\"cnn_model_fold_{fold + 1}.h5\")\n",
    "    print(f\"Model for fold {fold + 1} saved.\")\n",
    "\n",
    "    # Generate and store classification metrics\n",
    "    Y_val_pred = model.predict(X_val)\n",
    "    y_true = np.argmax(Y_val, axis=1)\n",
    "    y_pred = np.argmax(Y_val_pred, axis=1)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    for cls in report:\n",
    "        if cls in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "            continue\n",
    "        for metric in [\"precision\", \"recall\", \"f1-score\"]:\n",
    "            test_metrics_per_class[f\"{cls}_{metric}\"].append(report[cls][metric])\n",
    "\n",
    "# Plot average accuracy and loss across folds\n",
    "average_train_accuracy = np.mean([h.history[\"accuracy\"] for h in histories], axis=0)\n",
    "average_val_accuracy = np.mean([h.history[\"val_accuracy\"] for h in histories], axis=0)\n",
    "average_loss = np.mean([h.history[\"loss\"] for h in histories], axis=0)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(average_train_accuracy, label=\"Avg Train Accuracy\", color=\"green\")\n",
    "plt.plot(average_val_accuracy, label=\"Avg Val Accuracy\", linestyle=\"--\", color=\"blue\")\n",
    "plt.title(\"Average Accuracy Across Folds\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(average_loss, label=\"Avg Loss\", color=\"orange\")\n",
    "plt.title(\"Average Loss Across Folds\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"average_accuracy_loss_across_folds.png\")\n",
    "plt.close()\n",
    "\n",
    "# Print overall performance summary\n",
    "print(\"Average scores across all folds:\")\n",
    "print(f\"> Accuracy: {np.mean(acc_per_fold):.2f}% (± {np.std(acc_per_fold):.2f}%)\")\n",
    "print(f\"> Loss: {np.mean(loss_per_fold):.4f}\")\n",
    "\n",
    "# Display class-wise metrics with standard deviation\n",
    "print(\"\\nFinal Classification Report with Standard Deviation Across Folds:\")\n",
    "class_names = list(dataset.class_indices.keys())\n",
    "for i, cls in enumerate(class_names):\n",
    "    print(f\"\\nClass '{cls}' (Label {i}):\")\n",
    "    for metric in [\"precision\", \"recall\", \"f1-score\"]:\n",
    "        values = test_metrics_per_class[f\"{i}_{metric}\"]\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        print(f\"  {metric}: {mean_val:.4f} ± {std_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e37fed",
   "metadata": {},
   "source": [
    "The following script implements a CNN-based classification pipeline for GC-IMS heatmap images with repeated random train-test splits to assess the model's performance robustness. \n",
    "The pipeline includes model definition, image loading, training across multiple random splits, per-run evaluation and visualization, and statistical reporting of classification metrics (precision, recall, F1-score) with mean and standard deviation across multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Define the CNN model architecture\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(\n",
    "        layers.Conv2D(\n",
    "            8, (3, 3), strides=(1, 1), padding=\"same\", input_shape=input_shape\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(48, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(layers.Dense(32, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "input_shape = (248, 200, 3)\n",
    "num_classes = 3\n",
    "batch_size = 4\n",
    "epochs = 50\n",
    "\n",
    "# Create an ImageDataGenerator to rescale pixel values\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Path to dataset directory containing class subfolders\n",
    "data_dir = r\"Directory for final heatmaps\"\n",
    "\n",
    "# Number of repeated random train/test runs\n",
    "n_runs = 5\n",
    "overall_accuracies = []\n",
    "overall_losses = []\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "# Lists to store per-class metrics across runs\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_score_list = []\n",
    "\n",
    "# Repeat training/testing over multiple random splits\n",
    "for run in range(n_runs):\n",
    "\n",
    "    # Load all images and labels into memory\n",
    "    dataset = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(248, 200),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Store all image batches into arrays\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(dataset)):\n",
    "        x_batch, y_batch = dataset[i]\n",
    "        X.append(x_batch)\n",
    "        Y.append(y_batch)\n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    Y = np.concatenate(Y)\n",
    "\n",
    "    print(f\"\\nRun {run+1}/{n_runs} on random split:\")\n",
    "\n",
    "    # Create and compile the CNN model\n",
    "    cnn_model = create_cnn_model(input_shape, num_classes)\n",
    "    cnn_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    # Split data randomly into 80% train and 20% test\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.2, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Train the model and store training history\n",
    "    history = cnn_model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test, Y_test),\n",
    "    )\n",
    "\n",
    "    # Evaluate model on the test set\n",
    "    test_scores = cnn_model.evaluate(X_test, Y_test)\n",
    "    print(f\"Test loss: {test_scores[0]}\")\n",
    "    print(f\"Test accuracy: {test_scores[1]*100}%\")\n",
    "\n",
    "    # Save test accuracy and loss for this run\n",
    "    overall_accuracies.append(test_scores[1])\n",
    "    overall_losses.append(test_scores[0])\n",
    "\n",
    "    # Predict on test set\n",
    "    Y_pred = cnn_model.predict(X_test)\n",
    "    Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "    Y_true_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "    # Store predictions and ground truths for cumulative confusion matrix\n",
    "    all_true_labels.extend(Y_true_classes)\n",
    "    all_pred_labels.extend(Y_pred_classes)\n",
    "\n",
    "    # Generate and print classification report\n",
    "    print(f\"Classification Report for Run {run+1}:\")\n",
    "    report = classification_report(Y_true_classes, Y_pred_classes, output_dict=True)\n",
    "    print(report)\n",
    "\n",
    "    # Extract and store precision, recall, and F1-score per class\n",
    "    precision_list.append([report[str(i)][\"precision\"] for i in range(num_classes)])\n",
    "    recall_list.append([report[str(i)][\"recall\"] for i in range(num_classes)])\n",
    "    f1_score_list.append([report[str(i)][\"f1-score\"] for i in range(num_classes)])\n",
    "\n",
    "    # Confusion matrix for this run\n",
    "    cm = confusion_matrix(Y_true_classes, Y_pred_classes)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=dataset.class_indices.keys(),\n",
    "        yticklabels=dataset.class_indices.keys(),\n",
    "    )\n",
    "    plt.title(f\"Confusion Matrix for Run {run+1}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"confusion_matrix_run_{run+1}.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation accuracy/loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "    plt.plot(\n",
    "        history.history[\"val_accuracy\"], label=\"Validation Accuracy\", linestyle=\"--\"\n",
    "    )\n",
    "    plt.title(f\"Run {run+1} - Model Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\", linestyle=\"--\")\n",
    "    plt.title(f\"Run {run+1} - Model Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"accuracy_loss_plot_run_{run+1}.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Print mean accuracy and loss across runs\n",
    "print(\"\\nSummary of results from all runs:\")\n",
    "print(f\"Average accuracy: {np.mean(overall_accuracies)*100:.2f}%\")\n",
    "print(f\"Average loss: {np.mean(overall_losses):.4f}\")\n",
    "\n",
    "# Compute average and standard deviation of metrics\n",
    "precision_mean = np.mean(precision_list, axis=0)\n",
    "precision_std = np.std(precision_list, axis=0)\n",
    "recall_mean = np.mean(recall_list, axis=0)\n",
    "recall_std = np.std(recall_list, axis=0)\n",
    "f1_score_mean = np.mean(f1_score_list, axis=0)\n",
    "f1_score_std = np.std(f1_score_list, axis=0)\n",
    "\n",
    "# Display final classification report with error bars\n",
    "print(\"\\nOverall Classification Report (Mean ± Standard Deviation):\")\n",
    "print(\"Class\\tPrecision\\tRecall\\tF1-Score\")\n",
    "for i in range(num_classes):\n",
    "    print(\n",
    "        f\"{i}\\t{precision_mean[i]:.2f} ± {precision_std[i]:.2f}\\t{recall_mean[i]:.2f} ± {recall_std[i]:.2f}\\t{f1_score_mean[i]:.2f} ± {f1_score_std[i]:.2f}\"\n",
    "    )\n",
    "\n",
    "# Create and save the final cumulative confusion matrix\n",
    "overall_cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    overall_cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=dataset.class_indices.keys(),\n",
    "    yticklabels=dataset.class_indices.keys(),\n",
    ")\n",
    "plt.title(\"Overall Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"overall_confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5759a",
   "metadata": {},
   "source": [
    "The following script performs inference using a pre-trained CNN model on GC-IMS heatmap images.\n",
    "The pipeline includes model loading, preprocessing of test images using consistent normalization, generating predictions, mapping predicted indices to class labels, and saving the results to a CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7686ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define image parameters and model path\n",
    "image_size = (248, 200)  # Target size for image resizing (height, width)\n",
    "input_shape = (248, 200, 3)  # Shape expected by the model (H, W, Channels)\n",
    "batch_size = 4  # Must match the batch size used during training\n",
    "model_path = r\"Path to the trained CNN model\"\n",
    "\n",
    "# Load the trained model from file\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Set the path to the test image directory\n",
    "test_data_dir = r\"Directory containing test images organized in subfolders\"\n",
    "\n",
    "# Define preprocessing pipeline consistent with training\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Load test images using the data generator\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # No labels are used for prediction\n",
    "    shuffle=False,  # Ensure filenames and predictions remain aligned\n",
    ")\n",
    "\n",
    "# Generate predictions on the test dataset\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predicted_classes = np.argmax(\n",
    "    predictions, axis=1\n",
    ")\n",
    "\n",
    "# Map class indices to actual class labels\n",
    "class_indices = (\n",
    "    test_generator.class_indices\n",
    ") \n",
    "idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "predicted_labels = [\n",
    "    idx_to_class[i] for i in predicted_classes\n",
    "] \n",
    "\n",
    "# Retrieve filenames corresponding to the predictions\n",
    "filenames = test_generator.filenames\n",
    "\n",
    "# Display predictions alongside corresponding filenames\n",
    "for fname, pred_label in zip(filenames, predicted_labels):\n",
    "    print(f\"{fname} => {pred_label}\")\n",
    "\n",
    "# Optional: Save predictions and filenames to a CSV file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"Filename\": filenames, \"Predicted Class\": predicted_labels})\n",
    "df.to_csv(\"predictions.csv\", index=False)\n",
    "print(\"Predictions saved to predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f01ed",
   "metadata": {},
   "source": [
    "The following script generates class-specific saliency maps for GC-IMS heatmap images using a CNN model.\n",
    "It loads a model and test dataset, computes SmoothGrad-enhanced saliency maps using tf-keras-vis, and visualizes them with a custom colormap. The resulting heatmaps are saved with appropriate scientific axes and labels, enabling interpretation of which regions most influence the model's classification decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9666d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the trained CNN model\n",
    "model = tf.keras.models.load_model(r\"Path to the trained CNN model\")\n",
    "\n",
    "# Set up data generator for normalization and image loading\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "data_dir = r\"Directory for final heatmaps\"\n",
    "target_size = (248, 200)\n",
    "\n",
    "# Load dataset without shuffling to preserve order\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,  # Important: ensures filename-prediction alignment\n",
    ")\n",
    "\n",
    "# Create output directory for saving saliency maps\n",
    "output_dir = r\"Output directory for saving saliency maps\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize Saliency from tf-keras-vis\n",
    "saliency = Saliency(model)\n",
    "\n",
    "# Generate saliency maps for all images in the dataset\n",
    "for i in tqdm(range(len(val_generator)), desc=\"Generating saliency maps\"):\n",
    "    X_val, Y_val = val_generator[i]\n",
    "    class_index = np.argmax(Y_val)\n",
    "    filename = val_generator.filenames[i].replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "\n",
    "    # Define score function for the true class\n",
    "    score = CategoricalScore([class_index])\n",
    "\n",
    "    # Compute SmoothGrad-enhanced saliency map\n",
    "    saliency_map = saliency(score, X_val, smooth_samples=300, smooth_noise=0.05)[0]\n",
    "\n",
    "    # Custom colormap: white (low saliency) to red (high saliency)\n",
    "    white_to_red = LinearSegmentedColormap.from_list(\"white_red\", [\"white\", \"red\"])\n",
    "\n",
    "    # Apply cutoff threshold (optional)\n",
    "    cutoff = 0.0\n",
    "    saliency_map = np.maximum(saliency_map, cutoff)\n",
    "\n",
    "    # Plot saliency map with scientific axis formatting\n",
    "    fig, ax = plt.subplots(figsize=(4, 4), dpi=300)\n",
    "\n",
    "    im = ax.imshow(\n",
    "        saliency_map,\n",
    "        cmap=white_to_red,\n",
    "        vmin=cutoff,\n",
    "        vmax=saliency_map.max(),\n",
    "        extent=[1, 2.5, 50, 900],  # [dt_min, dt_max, rt_min, rt_max]\n",
    "        origin=\"upper\",\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "\n",
    "    # Axis labeling and tick formatting\n",
    "    ax.set_xlabel(\"Drift Time\")\n",
    "    ax.set_ylabel(\"Retention Time\")\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(20))\n",
    "    ax.tick_params(which=\"major\", length=6, labelsize=8)\n",
    "    ax.tick_params(which=\"minor\", length=3, labelsize=0)\n",
    "\n",
    "    # Colorbar with label\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"Saliency Intensity\", fontsize=8)\n",
    "    cbar.ax.tick_params(labelsize=6)\n",
    "\n",
    "    # Save plot to output directory\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(output_dir, f\"saliency_{filename}.png\"), bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96069914",
   "metadata": {},
   "source": [
    "The following script computes class-specific saliency maps for GC-IMS heatmap images using a trained CNN model. Instead of visualizing the saliency maps directly, it flattens each map into a 1D feature vector and groups them according to their predicted class. The resulting feature vectors are saved as NumPy arrays (.npy) per class, forming a structured representation of salient regions for each sample.\n",
    "\n",
    "Note:\n",
    "These saved matrices are used in the next section to perform PCA and generate a \"single representative image per class\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe575fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load trained CNN model\n",
    "model = tf.keras.models.load_model(r\"Path to the trained CNN model\")\n",
    "\n",
    "# Set up data generator for normalization and image loading\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "data_dir = r\"Directory for final heatmaps\"\n",
    "target_size = (248, 200)\n",
    "\n",
    "# Load dataset without shuffling to preserve order\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Prepare output directories for Feature matrices\n",
    "output_dir = r\"Output directory for saving feature matrices\"\n",
    "feature_output_dir = os.path.join(output_dir, \"Feature_Matrices\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(feature_output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize Saliency from tf-keras-vis\n",
    "saliency = Saliency(model)\n",
    "\n",
    "# Custom colormap: white (low saliency) to red (high saliency)\n",
    "white_to_red = LinearSegmentedColormap.from_list(\"white_red\", [\"white\", \"red\"])\n",
    "\n",
    "# Apply cutoff threshold (optional)\n",
    "cutoff = 0.0\n",
    "\n",
    "# Dictionary to collect flattened saliency vectors by class\n",
    "feature_matrices = {}\n",
    "\n",
    "# Generate saliency maps for all images in the dataset\n",
    "for i in tqdm(range(len(val_generator)), desc=\"Generating saliency maps\"):\n",
    "    X_val, Y_val = val_generator[i]\n",
    "    class_index = np.argmax(Y_val)\n",
    "    filename = val_generator.filenames[i].replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "\n",
    "    # Define score function for the current class\n",
    "    score = CategoricalScore([class_index])\n",
    "\n",
    "    # Compute SmoothGrad-enhanced saliency map\n",
    "    saliency_map = saliency(score, X_val, smooth_samples=300, smooth_noise=0.05)[0]\n",
    "\n",
    "    # Apply cutoff threshold\n",
    "    saliency_map = np.maximum(saliency_map, cutoff)\n",
    "\n",
    "    # Flatten saliency map to 1D vector\n",
    "    feature_vector = saliency_map.flatten()\n",
    "\n",
    "    # Collect feature vector under corresponding class\n",
    "    if class_index not in feature_matrices:\n",
    "        feature_matrices[class_index] = []\n",
    "    feature_matrices[class_index].append(feature_vector)\n",
    "\n",
    "# Save the feature matrices per class\n",
    "for class_idx, vectors in feature_matrices.items():\n",
    "    matrix = np.stack(vectors)  # shape: [num_samples, num_features]\n",
    "    np.save(\n",
    "        os.path.join(feature_output_dir, f\"class_{class_idx}_saliency_matrix.npy\"),\n",
    "        matrix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc3a98",
   "metadata": {},
   "source": [
    "The following script performs PCA on the class-specific saliency matrices generated earlier.\n",
    "Each matrix contains flattened saliency maps for one class, where rows represent samples and columns represent pixel-wise features. PCA is applied to reduce dimensionality and extract the dominant patterns across all samples of a class.\n",
    "The first principal component (PC1), also known as the loading vector, is reshaped back to the original image dimensions\n",
    "and visualized as a heatmap. This representative image highlights the most influential and class-discriminative regions\n",
    "across all saliency maps for that class.\n",
    "\n",
    "Note:\n",
    "These loading images serve as a \"single representative visualization per class\", revealing which regions of the GC-IMS\n",
    "heatmaps are consistently important across all samples in that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602cc07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Directory containing saved saliency feature matrices (one .npy file per class)\n",
    "feature_matrix_dir = r\"Input directory for feature matrices\"\n",
    "\n",
    "# Directory to store PCA loading images (output)\n",
    "pca_output_dir = r\"Directory to store PCA loading images output\"\n",
    "os.makedirs(pca_output_dir, exist_ok=True)\n",
    "\n",
    "# Original dimensions of the saliency maps\n",
    "height, width = 248, 200\n",
    "\n",
    "# Loop through all class-wise feature matrices\n",
    "for filename in os.listdir(feature_matrix_dir):\n",
    "    if filename.endswith(\".npy\") and filename.startswith(\"class_\"):\n",
    "        # Extract class index from filename\n",
    "        class_idx = filename.split(\"_\")[1]\n",
    "\n",
    "        # Load feature matrix: shape = (num_samples, height * width)\n",
    "        matrix = np.load(os.path.join(feature_matrix_dir, filename))\n",
    "\n",
    "        # Perform PCA on the feature matrix\n",
    "        pca = PCA()\n",
    "        pca.fit(matrix)\n",
    "\n",
    "        # Print explained variance ratio for reference (e.g., to verify PC1 contribution)\n",
    "        print(pca.explained_variance_ratio_)\n",
    "\n",
    "        # Extract the first principal component (loading vector)\n",
    "        pc1 = pca.components_[0].reshape((height, width))  # Reshape to image format\n",
    "\n",
    "        # Normalize PC1 to [-1, 1] for visualization\n",
    "        max_abs = np.max(np.abs(pc1))\n",
    "        pc1_normalized = pc1 / max_abs\n",
    "\n",
    "        # Create figure for visualization\n",
    "        fig, ax = plt.subplots(figsize=(4, 4), dpi=300)\n",
    "\n",
    "        # Display the normalized PC1 as a heatmap using a blue-white-red colormap\n",
    "        im = ax.imshow(\n",
    "            pc1_normalized,\n",
    "            cmap=\"bwr\",\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            extent=[1, 2.5, 50, 900],  # Drift time (x) and Retention time (y) axes\n",
    "            origin=\"upper\",  # Maintain correct axis direction\n",
    "            aspect=\"auto\",\n",
    "        )\n",
    "\n",
    "        # Axis labels\n",
    "        ax.set_xlabel(\"Drift time RIP relative (ms)\")\n",
    "        ax.set_ylabel(\"Retention Time (s)\")\n",
    "\n",
    "        # Set major and minor ticks for better interpretability\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "        ax.yaxis.set_minor_locator(ticker.MultipleLocator(20))\n",
    "\n",
    "        # Tweak tick appearance\n",
    "        ax.tick_params(which=\"major\", length=6, labelsize=8)\n",
    "        ax.tick_params(which=\"minor\", length=3, labelsize=0)\n",
    "\n",
    "        # Add colorbar to indicate saliency loading intensity\n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label(\"Saliency Intensity\", fontsize=8)\n",
    "        cbar.ax.tick_params(labelsize=6)\n",
    "\n",
    "        # Save the PC1 loading image for the class\n",
    "        save_path = os.path.join(pca_output_dir, f\"class_{class_idx}_pc1_loading.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Saved: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
